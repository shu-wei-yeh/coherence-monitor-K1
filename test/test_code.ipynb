{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.time import to_gps, from_gps\n",
    "from gwpy.segments import DataQualityFlag, SegmentList\n",
    "from gwpy.timeseries import TimeSeries, TimeSeriesDict\n",
    "from gwpy.frequencyseries import FrequencySeries\n",
    "import gwdatafind\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import plotly.express as px\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strain_data(starttime, endtime, duration, ifo='K1', source_gwf=None):\n",
    "    \"\"\"\n",
    "    Retrieve strain data for the interferometer K1 over the given time interval.\n",
    "\n",
    "    Parameters:\n",
    "      - starttime (float): Start time (GPS seconds).\n",
    "      - endtime (float): End time (GPS seconds).\n",
    "      - duration (float): Duration (in seconds) of the interval.\n",
    "      - ifo (str): Interferometer identifier (must be 'K1').\n",
    "      - source_gwf (str or list, optional): Path(s) to the GWF file(s).\n",
    "\n",
    "    Returns:\n",
    "      - TimeSeries: The strain data for the given time range.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ifo != 'K1':\n",
    "            raise ValueError(f\"Unsupported interferometer: {ifo}. Must be 'K1'.\")\n",
    "        \n",
    "        if source_gwf is None:\n",
    "            # Use the provided starttime and duration.\n",
    "            j = int(starttime)\n",
    "            computed_endtime = j + duration  \n",
    "            # Files are assumed to start every 32 seconds.\n",
    "            first_file = int(j - (j % 32))\n",
    "            last_file = int(computed_endtime - (computed_endtime % 32))\n",
    "            # Compute a block directory (adjust if necessary)\n",
    "            block = int((j - (j % 100000)) / 100000)\n",
    "            # Build a list of expected strain data file names.\n",
    "            \n",
    "            strain_channel_files = [\n",
    "                f\"/data/KAGRA/raw/science/{block}/K-K1_R-{i}-32.gwf\"\n",
    "                for i in range(first_file, last_file + 1, 32)\n",
    "            ]\n",
    "            # Filter for files that exist.\n",
    "            existing_files = [f for f in strain_channel_files if os.path.exists(f)]\n",
    "            if len(existing_files) == 0:\n",
    "                raise ValueError(\"No GWF files found for K1.\")\n",
    "            source_gwf = existing_files\n",
    "            print(f\"Selected strain data files: {source_gwf}\")\n",
    "        \n",
    "        # Read the strain data using TimeSeries.read (a single channel)\n",
    "        strain_channel = 'K1:CAL-CS_PROC_DARM_STRAIN_DBL_DQ'\n",
    "        ht = TimeSeries.read(\n",
    "            source=source_gwf,\n",
    "            channel=strain_channel,\n",
    "            start=starttime,\n",
    "            end=endtime\n",
    "        )\n",
    "        return ht\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in get_strain_data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strain_data = get_strain_data(1370183890, 1370183890+256, 256, 'K1', source_gwf=None)\n",
    "# print(strain_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_files(starttime, endtime, duration, ifo, directory=None):\n",
    "    \"\"\"\n",
    "    Retrieve frame (witness channel) files for the interferometer K1 over the given time interval.\n",
    "\n",
    "    Parameters:\n",
    "      - starttime (float): Start time (GPS seconds).\n",
    "      - endtime (float): End time (GPS seconds).\n",
    "      - duration (float): Duration (in seconds) of the interval.\n",
    "      - ifo (str): Interferometer identifier (must be 'K1').\n",
    "      - directory (str, optional): Directory path for witness channel data.\n",
    "\n",
    "    Returns:\n",
    "      - list: A sorted list of file paths.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ifo != 'K1':\n",
    "            raise ValueError(f\"Unsupported interferometer: {ifo}. Must be 'K1'.\")\n",
    "        if directory is None:\n",
    "            raise ValueError(\"A directory must be specified for 'K1' witness channel data.\")\n",
    "        if not os.path.isdir(directory):\n",
    "            raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "        \n",
    "        j = int(starttime)\n",
    "        computed_endtime = j + duration\n",
    "        first_file = int(j - (j % 32))\n",
    "        last_file = int(computed_endtime - (computed_endtime % 32))\n",
    "        block = int((j - (j % 100000)) / 100000)\n",
    "        # Build a list of expected witness channel file names.\n",
    "        witness_channel_files = [\n",
    "            f\"/data/KAGRA/raw/full/{block}/K-K1_C-{i}-32.gwf\"\n",
    "            for i in range(first_file, last_file + 1, 32)\n",
    "        ]\n",
    "        # Filter the list by checking file existence.\n",
    "        files = sorted([f for f in witness_channel_files if os.path.exists(f)])\n",
    "        return files\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in get_frame_files: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/data/KAGRA/raw/full/'\n",
    "# frame_file = get_frame_files(1370183890, 1370183890+256, 256, 'K1', directory=directory)\n",
    "# # print(list(check_witness_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coherence(channel2, frame_file, start_time, end_time, fft, overlap, strain_data, channel1=None):\n",
    "    t1 = to_gps(start_time)\n",
    "    t2 = to_gps(end_time)\n",
    "\n",
    "    if not isinstance(strain_data, TimeSeries):\n",
    "        raise ValueError(\"The parameter `strain_data` must be a `TimeSeries` object.\")\n",
    "    try:\n",
    "        ts2 = TimeSeriesDict.read(\n",
    "            frame_file,\n",
    "            channels=channel2,\n",
    "            start=t1,\n",
    "            end=t2\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Frame file not found: {frame_file}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read time series from {frame_file}: {e}\")\n",
    "    ts1 = strain_data.resample(ts2.sample_rate)\n",
    "    coh = ts1.coherence(\n",
    "        ts2,\n",
    "        fftlength=fft,\n",
    "        overlap=overlap,\n",
    "        window='hann'\n",
    "    )\n",
    "    return coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coherence(channel2, frame_files, start_time, end_time, fft, overlap, strain_data, channel1=None):\n",
    "    \"\"\"\n",
    "    Compute the coherence between strain data and witness (frame) data.\n",
    "\n",
    "    Parameters:\n",
    "      - channel2 (list or str): The witness channel(s) to be read.\n",
    "      - frame_files (str or list): The file path(s) for the witness channel data.\n",
    "      - start_time (float): Start time (GPS seconds).\n",
    "      - end_time (float): End time (GPS seconds).\n",
    "      - fft (float): The FFT length (in seconds) for the coherence calculation.\n",
    "      - overlap (float): The overlap (in seconds) between FFT segments.\n",
    "      - strain_data (TimeSeries): The strain data as a TimeSeries object.\n",
    "      - channel1: (Optional) Not used in this implementation.\n",
    "\n",
    "    Returns:\n",
    "      - FrequencySeries: The coherence between the strain data and witness data.\n",
    "    \"\"\"\n",
    "    # Convert start and end times to GPS-compatible times\n",
    "    t1 = to_gps(start_time)\n",
    "    t2 = to_gps(end_time)\n",
    "    \n",
    "    # Read the witness (frame) data using TimeSeriesDict.read.\n",
    "    # Note: frame_files can be a single file or a list of files.\n",
    "    try:\n",
    "        ts2 = TimeSeriesDict.read(\n",
    "            frame_files,\n",
    "            channels=channel2,\n",
    "            start=t1,\n",
    "            end=t2\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Frame file not found: {frame_files}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read time series from {frame_files}: {e}\")\n",
    "    \n",
    "    # Extract the sample rate from one of the witness channels.\n",
    "    # (Assumes all witness channels share the same sample rate.)\n",
    "    witness_sample_rate = list(ts2.values())[0].sample_rate\n",
    "\n",
    "    # Resample the strain data if needed.\n",
    "    if strain_data.sample_rate != witness_sample_rate:\n",
    "        strain_data = strain_data.resample(witness_sample_rate)\n",
    "    \n",
    "    # Compute coherence using the resampled strain data and the witness data.\n",
    "    coh = TimeSeries.coherence(\n",
    "        strain_data,\n",
    "        frame_files,\n",
    "        fftlength=fft,\n",
    "        overlap=overlap,\n",
    "        window='hann'\n",
    "        )\n",
    "    return coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwpy.time import to_gps, from_gps\n",
    "from gwpy.segments import DataQualityFlag, SegmentList\n",
    "from gwpy.timeseries import TimeSeries, TimeSeriesDict\n",
    "from gwpy.frequencyseries import FrequencySeries\n",
    "import gwdatafind\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "def get_strain_data(starttime, endtime, duration, ifo='K1', source_gwf=None):\n",
    "    \"\"\"\n",
    "    Retrieve strain data for the interferometer K1 over the given time interval.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ifo != 'K1':\n",
    "            raise ValueError(f\"Unsupported interferometer: {ifo}. Must be 'K1'.\")\n",
    "        \n",
    "        if source_gwf is None:\n",
    "            # Use the provided starttime and duration.\n",
    "            j = int(starttime)\n",
    "            computed_endtime = j + duration  \n",
    "            # Files are assumed to start every 32 seconds.\n",
    "            first_file = int(j - (j % 32))\n",
    "            last_file = int(computed_endtime - (computed_endtime % 32))\n",
    "            # Compute a block directory (adjust if necessary)\n",
    "            block = int((j - (j % 100000)) / 100000)\n",
    "            # Build a list of expected strain data file names.\n",
    "            strain_channel_files = [\n",
    "                f\"/data/KAGRA/raw/science/{block}/K-K1_R-{i}-32.gwf\"\n",
    "                for i in range(first_file, last_file + 1, 32)\n",
    "            ]\n",
    "            # Filter for files that exist.\n",
    "            existing_files = [f for f in strain_channel_files if os.path.exists(f)]\n",
    "            if len(existing_files) == 0:\n",
    "                raise ValueError(\"No GWF files found for K1.\")\n",
    "            source_gwf = existing_files\n",
    "            print(f\"Selected strain data files: {source_gwf}\")\n",
    "        \n",
    "        # Read the strain data using TimeSeries.read (a single channel)\n",
    "        strain_channel = 'K1:CAL-CS_PROC_DARM_STRAIN_DBL_DQ'\n",
    "        ht = TimeSeries.read(\n",
    "            source=source_gwf,\n",
    "            channel=strain_channel,\n",
    "            start=starttime,\n",
    "            end=endtime\n",
    "        )\n",
    "        return ht\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in get_strain_data: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_frame_files(starttime, endtime, duration, ifo, directory=None):\n",
    "    \"\"\"\n",
    "    Retrieve frame (witness channel) files for the interferometer K1 over the given time interval.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ifo != 'K1':\n",
    "            raise ValueError(f\"Unsupported interferometer: {ifo}. Must be 'K1'.\")\n",
    "        if directory is None:\n",
    "            raise ValueError(\"A directory must be specified for 'K1' witness channel data.\")\n",
    "        if not os.path.isdir(directory):\n",
    "            raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "        \n",
    "        j = int(starttime)\n",
    "        computed_endtime = j + duration\n",
    "        first_file = int(j - (j % 32))\n",
    "        last_file = int(computed_endtime - (computed_endtime % 32))\n",
    "        block = int((j - (j % 100000)) / 100000)\n",
    "        # Build a list of expected witness channel file names.\n",
    "        witness_channel_files = [\n",
    "            f\"/data/KAGRA/raw/full/{block}/K-K1_C-{i}-32.gwf\"\n",
    "            for i in range(first_file, last_file + 1, 32)\n",
    "        ]\n",
    "        # Filter the list by checking file existence.\n",
    "        files = sorted([f for f in witness_channel_files if os.path.exists(f)])\n",
    "        return files\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in get_frame_files: {e}\")\n",
    "        return []\n",
    "\n",
    "def calc_coherence(channel2, frame_files, start_time, end_time, fft, overlap, strain_data, channel1=None):\n",
    "    \"\"\"\n",
    "    Compute the coherence between strain data and all witness (frame) channels.\n",
    "\n",
    "    Parameters:\n",
    "      - channel2 (list or str): The witness channel(s) to be read.\n",
    "      - frame_files (str or list): The file path(s) for the witness channel data.\n",
    "      - start_time (float): Start time (GPS seconds).\n",
    "      - end_time (float): End time (GPS seconds).\n",
    "      - fft (float): The FFT length (in seconds) for the coherence calculation.\n",
    "      - overlap (float): The overlap (in seconds) between FFT segments.\n",
    "      - strain_data (TimeSeries): The strain data as a TimeSeries object.\n",
    "      - channel1: (Optional) Not used in this implementation.\n",
    "\n",
    "    Returns:\n",
    "      - dict: A dictionary where keys are witness channel names and values are the corresponding coherence FrequencySeries.\n",
    "    \"\"\"\n",
    "    from gwpy.time import to_gps\n",
    "\n",
    "    # Convert start and end times to GPS-compatible times.\n",
    "    t1 = to_gps(start_time)\n",
    "    t2 = to_gps(end_time)\n",
    "\n",
    "    if not isinstance(strain_data, TimeSeries):\n",
    "        raise ValueError(\"The parameter `strain_data` must be a TimeSeries object.\")\n",
    "\n",
    "    try:\n",
    "        # Read the witness (frame) data into a TimeSeriesDict.\n",
    "        ts2 = TimeSeriesDict.read(\n",
    "            frame_files,\n",
    "            channels=channel2,\n",
    "            start=t1,\n",
    "            end=t2\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Frame file(s) not found: {frame_files}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to read time series from {frame_files}: {e}\")\n",
    "\n",
    "    coh = {}\n",
    "    # Loop over each witness channel in the TimeSeriesDict.\n",
    "    for chan_name, witness_ts in ts2.items():\n",
    "        # Get the sample rate for the current witness channel.\n",
    "        witness_sample_rate = witness_ts.sample_rate\n",
    "\n",
    "        # Resample the strain data to match the witness channel's sample rate.\n",
    "        ts1_resampled = strain_data.resample(witness_sample_rate)\n",
    "\n",
    "        # Compute the coherence between the resampled strain data and the witness channel.\n",
    "        coherence = ts1_resampled.coherence(\n",
    "            witness_ts,\n",
    "            fftlength=fft,\n",
    "            overlap=overlap,\n",
    "            window='hann'\n",
    "        )\n",
    "        coh[chan_name] = coherence\n",
    "\n",
    "    return coh\n",
    "\n",
    "## test ##\n",
    "from gwpy.time import to_gps\n",
    "import os\n",
    "\n",
    "def run_coherence(channel_list, frame_files, starttime, endtime, strain_data, savedir, ifo, fft=10, overlap=5):\n",
    "    \"\"\"\n",
    "    Calculate and save the coherence between strain data and witness channels.\n",
    "    \n",
    "    This function calculates the coherence between the given strain data and all witness channels \n",
    "    specified in `channel_list` (using the frame files). The coherence for each witness channel is \n",
    "    saved as a CSV file in a subdirectory of `savedir` based on the start time.\n",
    "    \n",
    "    Parameters:\n",
    "      - channel_list (list): A list of witness channel names.\n",
    "      - frame_files (str or list): The file path(s) for the witness channel data.\n",
    "      - starttime (float): Start time in GPS seconds.\n",
    "      - endtime (float): End time in GPS seconds.\n",
    "      - strain_data (TimeSeries): The strain data as a TimeSeries object.\n",
    "      - savedir (str): The base directory to save output files.\n",
    "      - ifo (str): The interferometer identifier (must be 'K1').\n",
    "      - fft (float, optional): The FFT length (in seconds) for the coherence calculation.\n",
    "      - overlap (float, optional): The overlap (in seconds) between FFT segments.\n",
    "    \"\"\"\n",
    "    # Convert start and end times to GPS times for naming and output.\n",
    "    t1, t2 = to_gps(starttime), to_gps(endtime)\n",
    "    \n",
    "    # Create an output directory based on the start time.\n",
    "    outdir = os.path.join(savedir, f'{t1}')\n",
    "    if not os.path.exists(outdir):\n",
    "        print(f\"Creating the output directory: {outdir}\")\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "    # Determine the strain channel name.\n",
    "    if ifo == 'K1':\n",
    "        strain_channel = f'{ifo}:CAL-CS_PROC_DARM_STRAIN_DBL_DQ'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported interferometer: {ifo}. Must be 'K1'.\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"Calculating coherence for witness channels: {', '.join(channel_list)} ...\")\n",
    "        # Call the updated calc_coherence with the full channel list.\n",
    "        # Note: We pass the original starttime and endtime so that calc_coherence\n",
    "        # can perform its own conversion.\n",
    "        coherence_dict = calc_coherence(\n",
    "            channel2=channel_list,\n",
    "            frame_files=frame_files,\n",
    "            start_time=starttime,\n",
    "            end_time=endtime,\n",
    "            fft=fft,\n",
    "            overlap=overlap,\n",
    "            strain_data=strain_data,\n",
    "            channel1=None\n",
    "        )\n",
    "        \n",
    "        # Iterate over each channel's coherence result and save the output.\n",
    "        for chan, coh in coherence_dict.items():\n",
    "            # Sanitize the channel name to create a valid filename.\n",
    "            sanitized_channel = chan.replace(':', '_').replace('-', '_')\n",
    "            output_file = os.path.join(outdir, f\"{sanitized_channel}_{t1}_{t2}.csv\")\n",
    "            coh.write(output_file)\n",
    "            print(f\"Saved coherence data for {chan} to {output_file}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate or save coherence: {e}\")\n",
    "\n",
    "## test ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected strain data files: ['/data/KAGRA/raw/science/13701/K-K1_R-1370183872-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370183904-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370183936-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370183968-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184000-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184032-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184064-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184096-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184128-32.gwf']\n"
     ]
    }
   ],
   "source": [
    "# ----- Usage Example -----\n",
    "start_time = 1370183890\n",
    "end_time = start_time + 256\n",
    "channel_path = '/home/shu-wei.yeh/coherence-monitor/channel_files/K1/'\n",
    "fft, overlap = 2, 1\n",
    "\n",
    "# Read the channel CSV and convert the 'channel' column to a list.\n",
    "channels_df = pd.read_csv(os.path.join(channel_path, 'volt_channels.csv'),\n",
    "                          header=None, names=['channel'])\n",
    "channel_list = channels_df['channel'].tolist()\n",
    "\n",
    "duration = 256  # seconds\n",
    "\n",
    "# Retrieve the strain data.\n",
    "strain_data = get_strain_data(start_time, end_time, duration, ifo='K1', source_gwf=None)\n",
    "if strain_data is None:\n",
    "    raise RuntimeError(\"Strain data could not be loaded. Please check that the GWF files exist.\")\n",
    "\n",
    "# Retrieve the witness (frame) files.\n",
    "witness_directory = '/data/KAGRA/raw/full/'  # Adjust this path as needed.\n",
    "frame_files = get_frame_files(start_time, end_time, duration, ifo='K1', directory=witness_directory)\n",
    "if not frame_files:\n",
    "    raise RuntimeError(\"No witness frame files were found. Please check the directory and file availability.\")\n",
    "\n",
    "# Compute coherence using the full list of frame files.\n",
    "coherence = calc_coherence(channel_list, frame_files, start_time, end_time, fft, overlap, strain_data)\n",
    "# print(\"Coherence calculation successful!\")\n",
    "# print(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating coherence for witness channels: K1:PEM-VOLT_AS_TABLE_GND_OUT_DQ, K1:PEM-VOLT_IMCREFL_TABLE_GND_OUT_DQ, K1:PEM-VOLT_ISS_TABLE_GND_OUT_DQ, K1:PEM-VOLT_OMC_CHAMBER_GND_OUT_DQ, K1:PEM-VOLT_PSL_TABLE_GND_OUT_DQ, K1:PEM-VOLT_REFL_TABLE_GND_OUT_DQ ...\n",
      "Saved coherence data for K1:PEM-VOLT_AS_TABLE_GND_OUT_DQ to ./K1_automatic/1370183890/K1_PEM_VOLT_AS_TABLE_GND_OUT_DQ_1370183890_1370184146.csv\n",
      "Saved coherence data for K1:PEM-VOLT_IMCREFL_TABLE_GND_OUT_DQ to ./K1_automatic/1370183890/K1_PEM_VOLT_IMCREFL_TABLE_GND_OUT_DQ_1370183890_1370184146.csv\n",
      "Saved coherence data for K1:PEM-VOLT_ISS_TABLE_GND_OUT_DQ to ./K1_automatic/1370183890/K1_PEM_VOLT_ISS_TABLE_GND_OUT_DQ_1370183890_1370184146.csv\n",
      "Saved coherence data for K1:PEM-VOLT_OMC_CHAMBER_GND_OUT_DQ to ./K1_automatic/1370183890/K1_PEM_VOLT_OMC_CHAMBER_GND_OUT_DQ_1370183890_1370184146.csv\n",
      "Saved coherence data for K1:PEM-VOLT_PSL_TABLE_GND_OUT_DQ to ./K1_automatic/1370183890/K1_PEM_VOLT_PSL_TABLE_GND_OUT_DQ_1370183890_1370184146.csv\n",
      "Saved coherence data for K1:PEM-VOLT_REFL_TABLE_GND_OUT_DQ to ./K1_automatic/1370183890/K1_PEM_VOLT_REFL_TABLE_GND_OUT_DQ_1370183890_1370184146.csv\n"
     ]
    }
   ],
   "source": [
    "starttime = 1370183890\n",
    "endtime = start_time + 256\n",
    "savedir = './K1_automatic'\n",
    "run_coh = run_coherence(channel_list, frame_files, starttime, endtime, strain_data, savedir, ifo='K1', fft=10, overlap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_corr(output_dir, save=False):\n",
    "    \"\"\"\n",
    "    Process all CSV files in `output_dir` to compute the maximum correlation value\n",
    "    (and its corresponding frequency) over a default frequency band from 1 Hz to 200 Hz.\n",
    "    \n",
    "    Parameters:\n",
    "      output_dir (str): Directory containing CSV files.\n",
    "      save (bool): If True, return a DataFrame of channels with max correlation > 0.\n",
    "    \n",
    "    Returns:\n",
    "      DataFrame: If save is True, a DataFrame with columns ['channel', 'max_correlation', 'frequency'];\n",
    "                 otherwise, an empty DataFrame.\n",
    "    \"\"\"\n",
    "    # Use an absolute path for consistency.\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "    files = glob.glob(os.path.join(output_dir, '*.csv'))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in directory: {output_dir}\")\n",
    "    \n",
    "    vals = []\n",
    "    for file_path in files:\n",
    "        try:\n",
    "            # Extract a channel name by splitting on 'DQ'\n",
    "            base = os.path.basename(file_path)\n",
    "            chan_name = base.split('DQ')[0] + 'DQ'\n",
    "            \n",
    "            # Read the FrequencySeries saved in the CSV file.\n",
    "            fs = FrequencySeries.read(file_path)\n",
    "            \n",
    "            # Check that there are at least two frequency points to determine the spacing.\n",
    "            if len(fs.frequencies) < 2:\n",
    "                raise ValueError(\"Insufficient frequency points in FrequencySeries.\")\n",
    "            \n",
    "            # Compute the frequency difference using the first two frequency points.\n",
    "            n1, n2 = fs.frequencies.value[0], fs.frequencies.value[1]\n",
    "            n_diff = n2 - n1\n",
    "            \n",
    "            # For the default frequency band of 1 Hz to 200 Hz:\n",
    "            ind1, ind2 = int(1 / n_diff), int(200 / n_diff)\n",
    "            fs_sub = fs[ind1:ind2]\n",
    "            \n",
    "            max_value = fs_sub.max().value\n",
    "            max_value_frequency = fs_sub.frequencies[fs_sub.argmax()].value\n",
    "            \n",
    "            if save and max_value > 0:\n",
    "                vals.append((chan_name, max_value, max_value_frequency))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {file_path}: {e}\")\n",
    "    \n",
    "    if save:\n",
    "        df_vals = pd.DataFrame(vals, columns=['channel', 'max_correlation', 'frequency'])\n",
    "        return df_vals[df_vals['max_correlation'] > 0]\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_max_corr_band(output_dir, flow=10, fhigh=20, save=False):\n",
    "    \"\"\"\n",
    "    Process all CSV files in `output_dir` to compute the maximum correlation value\n",
    "    (and its corresponding frequency) within a specified frequency band.\n",
    "    \n",
    "    Parameters:\n",
    "      output_dir (str): Directory containing CSV files.\n",
    "      flow (float): Lower bound of the frequency band.\n",
    "      fhigh (float): Upper bound of the frequency band.\n",
    "      save (bool): If True, return a DataFrame of channels with max correlation > 0.\n",
    "    \n",
    "    Returns:\n",
    "      DataFrame: If save is True, a DataFrame with columns ['channel', 'max_correlation', 'frequency'];\n",
    "                 otherwise, an empty DataFrame.\n",
    "    \"\"\"\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "    files = glob.glob(os.path.join(output_dir, '*.csv'))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in directory: {output_dir}\")\n",
    "    \n",
    "    vals = []\n",
    "    for file_path in files:\n",
    "        try:\n",
    "            base = os.path.basename(file_path)\n",
    "            chan_name = base.split('DQ')[0] + 'DQ'\n",
    "            \n",
    "            fs = FrequencySeries.read(file_path)\n",
    "            if len(fs.frequencies) < 2:\n",
    "                raise ValueError(\"Insufficient frequency points in FrequencySeries.\")\n",
    "            \n",
    "            n1, n2 = fs.frequencies.value[0], fs.frequencies.value[1]\n",
    "            n_diff = n2 - n1\n",
    "            \n",
    "            # Compute indices corresponding to the desired frequency band [flow, fhigh]\n",
    "            ind1, ind2 = int(flow / n_diff), int(fhigh / n_diff)\n",
    "            fs_sub = fs[ind1:ind2]\n",
    "            \n",
    "            max_value = fs_sub.max().value\n",
    "            max_value_frequency = fs_sub.frequencies[fs_sub.argmax()].value\n",
    "            \n",
    "            if save and max_value > 0:\n",
    "                vals.append((chan_name, max_value, max_value_frequency))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process file {file_path}: {e}\")\n",
    "    \n",
    "    if save:\n",
    "        df_vals = pd.DataFrame(vals, columns=['channel', 'max_correlation', 'frequency'])\n",
    "        return df_vals[df_vals['max_correlation'] > 0]\n",
    "    \n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(dir_path, ifo):\n",
    "    \"\"\"\n",
    "    Combine CSV files in the given directory after filtering out unsafe channels.\n",
    "    \n",
    "    Parameters:\n",
    "      - dir_path (str): Directory containing CSV files.\n",
    "      - ifo (str): Interferometer identifier (used to filter unsafe channels).\n",
    "    \n",
    "    Returns:\n",
    "      DataFrame: A combined DataFrame whose columns are renamed based on each file.\n",
    "    \"\"\"\n",
    "    # Use absolute path for consistency.\n",
    "    dir_path = os.path.abspath(dir_path)\n",
    "    all_files = glob.glob(os.path.join(dir_path, \"*.csv\"))\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in directory: {dir_path}\")\n",
    "    \n",
    "    # Get the list of unsafe channels and sanitize their names.\n",
    "    chan_removes = get_unsafe_channels(ifo=ifo)['channel']\n",
    "    chan_removes = [chan.replace(':', '_').replace('-', '_') for chan in chan_removes]\n",
    "    \n",
    "    # Filter out files whose basenames start with any unsafe channel.\n",
    "    filtered_files = [\n",
    "        file for file in all_files\n",
    "        if not any(os.path.basename(file).startswith(chan) for chan in chan_removes)\n",
    "    ]\n",
    "    if not filtered_files:\n",
    "        raise ValueError(\"No valid CSV files found after filtering unsafe channels.\")\n",
    "    \n",
    "    combined_data = []\n",
    "    column_names = []\n",
    "    for file_path in filtered_files:\n",
    "        try:\n",
    "            # Use part of the filename to generate column names.\n",
    "            base_name = os.path.basename(file_path).split('_14')[0]\n",
    "            column_freq = f\"{base_name}_freq\"\n",
    "            column_corr = f\"{base_name}_corr\"\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            combined_data.append(df)\n",
    "            column_names.extend([column_freq, column_corr])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "    \n",
    "    if not combined_data:\n",
    "        raise ValueError(\"No CSV files could be processed.\")\n",
    "    \n",
    "    # Concatenate dataframes side by side.\n",
    "    combined_df = pd.concat(combined_data, axis=1, ignore_index=True)\n",
    "    if combined_df.shape[1] != len(column_names):\n",
    "        raise ValueError(\"Mismatch between the number of columns and column names.\")\n",
    "    combined_df.columns = column_names\n",
    "    return combined_df\n",
    "\n",
    "def find_max_corr_channel(path, ifo, fft=10):\n",
    "    \"\"\"\n",
    "    Find, for each frequency bin, the channels with the highest and second-highest coherence.\n",
    "    \n",
    "    Parameters:\n",
    "      - path (str): Directory containing CSV files.\n",
    "      - ifo (str): Interferometer identifier.\n",
    "      - fft (float): FFT length used to compute frequency bins.\n",
    "    \n",
    "    Returns:\n",
    "      DataFrame: A DataFrame with columns ['frequency', 'channel1', 'corr1', 'channel2', 'corr2'].\n",
    "    \"\"\"\n",
    "    frame_df = combine_csv(path, ifo)\n",
    "    if frame_df.empty:\n",
    "        raise ValueError(f\"No valid data found in the combined CSV files at {path}.\")\n",
    "    \n",
    "    max_vals = []\n",
    "    # Loop over each row (each frequency bin).\n",
    "    for i in range(len(frame_df)):\n",
    "        try:\n",
    "            # Assume that every second column (starting with index 1) holds coherence values.\n",
    "            corr_values = frame_df.iloc[i, 1::2]\n",
    "            # Sort descending by coherence.\n",
    "            corr_sorted = corr_values.sort_values(ascending=False)\n",
    "            # Get the top two channel column indices.\n",
    "            top_columns = corr_sorted.index[:2]\n",
    "            # Reconstruct channel names from the column names.\n",
    "            chan_names = [\n",
    "                col.replace('_corr', '').replace(f'{ifo}_', f'{ifo}:')\n",
    "                for col in top_columns\n",
    "            ]\n",
    "            max_corr_vals = corr_sorted.iloc[:2].tolist()\n",
    "            # Compute the frequency (row index divided by the FFT length).\n",
    "            freq = i / fft\n",
    "            max_vals.append((freq, chan_names[0], max_corr_vals[0],\n",
    "                             chan_names[1], max_corr_vals[1]))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {i}: {e}\")\n",
    "            continue\n",
    "    df_max = pd.DataFrame(max_vals, columns=['frequency', 'channel1', 'corr1', 'channel2', 'corr2'])\n",
    "    return df_max\n",
    "\n",
    "def plot_max_corr_chan(path, fft, ifo, flow=0, fhigh=200, duration=256):\n",
    "    \"\"\"\n",
    "    Plot the highest and second-highest coherence channels across frequency bins.\n",
    "    \n",
    "    Parameters:\n",
    "      - path (str): Directory containing CSV files.\n",
    "      - fft (float): FFT length (used in frequency calculation).\n",
    "      - ifo (str): Interferometer identifier.\n",
    "      - flow (float): Lower frequency bound for plotting.\n",
    "      - fhigh (float): Upper frequency bound for plotting.\n",
    "      - duration (int): Duration used in plot titles.\n",
    "    \n",
    "    Returns:\n",
    "      DataFrame: The DataFrame of maximum correlation channel data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Assume the directory name is a timestamp.\n",
    "        time_ = int(os.path.basename(os.path.normpath(path)))\n",
    "        vals = find_max_corr_channel(path=path, fft=fft, ifo=ifo)\n",
    "        print(\"Data acquired; generating plots...\")\n",
    "        # Filter rows by frequency.\n",
    "        vals = vals[(vals['frequency'] >= flow) & (vals['frequency'] <= fhigh)]\n",
    "        \n",
    "        # Apply a grouping function to channels (assumes give_group_v2 is defined).\n",
    "        vals['group1'] = vals['channel1'].apply(give_group_v2)\n",
    "        vals['group2'] = vals['channel2'].apply(give_group_v2)\n",
    "        \n",
    "        # Plot highest coherence channel.\n",
    "        fig1 = px.scatter(\n",
    "            vals,\n",
    "            x=\"frequency\",\n",
    "            y=\"corr1\",\n",
    "            hover_data=['channel1'],\n",
    "            color=\"group1\",\n",
    "            labels={\"corr1\": \"Max Coherence\", \"frequency\": \"Frequency [Hz]\"}\n",
    "        )\n",
    "        fig1.update_layout(\n",
    "            title={\n",
    "                \"text\": f\"Highest Coherence Channel at Each Frequency ({time_} to {time_ + duration})\",\n",
    "                \"font\": {\"family\": \"Courier New, monospace\", \"size\": 28, \"color\": \"RebeccaPurple\"}\n",
    "            },\n",
    "            font_size=28\n",
    "        )\n",
    "        \n",
    "        # Plot second-highest coherence channel.\n",
    "        fig2 = px.scatter(\n",
    "            vals,\n",
    "            x=\"frequency\",\n",
    "            y=\"corr2\",\n",
    "            hover_data=['channel2'],\n",
    "            color=\"group2\",\n",
    "            labels={\"corr2\": \"Second Max Coherence\", \"frequency\": \"Frequency [Hz]\"}\n",
    "        )\n",
    "        fig2.update_layout(\n",
    "            title={\n",
    "                \"text\": f\"Second Highest Coherence Channel at Each Frequency ({time_} to {time_ + duration})\",\n",
    "                \"font\": {\"family\": \"Courier New, monospace\", \"size\": 28, \"color\": \"RebeccaPurple\"}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Create a subdirectory for plots.\n",
    "        plot_dir = os.path.join(path, \"plots\")\n",
    "        os.makedirs(plot_dir, exist_ok=True)\n",
    "        plotly.offline.plot(fig1, filename=os.path.join(plot_dir, f'channels_coh_{time_}_a.html'))\n",
    "        plotly.offline.plot(fig2, filename=os.path.join(plot_dir, f'channels_coh_{time_}_b.html'))\n",
    "        print(\"Plots saved successfully.\")\n",
    "        return vals\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during plotting: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your functions (adjust the module name if needed)\n",
    "# from your_module import get_strain_data, get_frame_files, calc_coherence\n",
    "\n",
    "# --- Provided parameters ---\n",
    "start_time = 1370183890\n",
    "end_time = start_time + 256\n",
    "channel_path = '/home/shu-wei.yeh/coherence-monitor/channel_files/K1/'\n",
    "fft, overlap = 2, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the channel CSV and convert the channel column to a list of strings.\n",
    "# (TimeSeriesDict.read expects channel names as a list of strings.)\n",
    "channels_df = pd.read_csv(os.path.join(channel_path, 'volt_channels.csv'),\n",
    "                          header=None, names=['channel'])\n",
    "channel_list = channels_df['channel'].tolist()\n",
    "# print(channel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected strain data files: ['/data/KAGRA/raw/science/13701/K-K1_R-1370183872-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370183904-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370183936-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370183968-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184000-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184032-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184064-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184096-32.gwf', '/data/KAGRA/raw/science/13701/K-K1_R-1370184128-32.gwf']\n"
     ]
    }
   ],
   "source": [
    "# --- Retrieve the strain data ---\n",
    "# You may need to set source_gwf to None (or to a list of valid files)\n",
    "duration = 256  # seconds\n",
    "strain_data = get_strain_data(start_time, end_time, duration, ifo='K1', source_gwf=None)\n",
    "# print(len(strain_data))\n",
    "\n",
    "if strain_data is None:\n",
    "    raise RuntimeError(\"Strain data could not be loaded. Check that the GWF files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# --- Retrieve witness (frame) files ---\n",
    "# Make sure to update witness_directory to a valid directory on your system.\n",
    "witness_directory = '/data/KAGRA/raw/full/'  # Adjust this path as needed.\n",
    "frame_files = get_frame_files(start_time, end_time, duration, ifo='K1', directory=witness_directory)\n",
    "\n",
    "if not frame_files:\n",
    "    raise RuntimeError(\"No witness frame files were found. Please check the directory and file availability.\")\n",
    "\n",
    "# For this test, we take the first available frame file.\n",
    "frame_file = frame_files\n",
    "print(len(frame_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during coherence calculation: 'TimeSeriesDict' object has no attribute 'sample_rate'\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Coherence ---\n",
    "try:\n",
    "    # Note: We pass 'channel_list' instead of the raw DataFrame.\n",
    "    coherence = calc_coherence(channel_list, frame_file, start_time, end_time, fft, overlap, strain_data)\n",
    "    print(\"Coherence calculation successful!\")\n",
    "    print(coherence)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during coherence calculation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_coherence(channel_list, frame_files, starttime, endtime, strain_data, savedir, ifo, fft=fft, overlap=overlap):\n",
    "    t1, t2 = to_gps(starttime), to_gps(endtime)\n",
    "    savedir = os.path.join(savedir, f'{t1}')\n",
    "    if not os.path.exists(savedir):\n",
    "        print(f\"Creating the output directory: {savedir}\")\n",
    "        os.makedirs(savedir)\n",
    "    if ifo == 'K1':\n",
    "        strain_channel = f'{ifo}:CAL-CS_PROC_DARM_STRAIN_DBL_DQ'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported interferometer: {ifo}. Must be 'K1'.\")\n",
    "    for channel in channel_list:\n",
    "        try:\n",
    "            print(f\"Calculating coherence between {strain_channel} and {channel}...\")\n",
    "            coh = calc_coherence(\n",
    "                strain_data=strain_data,\n",
    "                channel1=None,\n",
    "                channel2=channel,\n",
    "                frame_file=frame_files,\n",
    "                start_time=t1,\n",
    "                end_time=t2,\n",
    "                fft=fft,\n",
    "                overlap=overlap\n",
    "            )\n",
    "            sanitized_channel = channel.replace(':', '_').replace('-', '_')\n",
    "            output_file = os.path.join(savedir, f\"{sanitized_channel}_{t1}_{t2}.csv\")\n",
    "            coh.write(output_file)\n",
    "            print(f\"Saved coherence data to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to calculate or save coherence for {channel}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 1370183890\n",
    "end_time = start_time + 256\n",
    "channel_path = '/home/shu-wei.yeh/coherence-monitor/channel_files/K1/'\n",
    "channel2 = pd.read_csv(os.path.join(channel_path, 'volt_channels.csv'), header=None, names=['channel'])\n",
    "fft, overlap = 2, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_calc_coherence = calc_coherence(channel2, frame_file, start_time, end_time, fft, overlap, strain_data, channel1=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ht_data = get_strain_data(time_, time_ + duration, duration, ifo=ifo)\n",
    "# print(\"Got h(t) data\")\n",
    "\n",
    "# def give_group(a):\n",
    "#     return a.split('_')[1]\n",
    "\n",
    "# def get_coherence_volt(channel_list, ifo, t0, strain_data, savedir, duration):\n",
    "#     # Get witness files from the specified directory over the interval [t0, t0+duration)\n",
    "#     files_ = get_frame_files(t0, t0 + duration, duration, ifo=ifo, directory='/data/KAGRA/raw/full/')\n",
    "#     print(\"Got {} files\".format(len(files_)))\n",
    "#     if not files_:\n",
    "#         raise ValueError(\"No frame files found.\")\n",
    "#     # *** FIX: Pass the entire list of files, not just the first file ***\n",
    "#     run_coherence(\n",
    "#         channel_list=channel_list,\n",
    "#         frame_files=files_[0],\n",
    "#         starttime=t0,\n",
    "#         endtime=t0 + duration,\n",
    "#         ifo=ifo,\n",
    "#         strain_data=strain_data,\n",
    "#         savedir=savedir\n",
    "#     )\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEM-VOLT\n"
     ]
    }
   ],
   "source": [
    "channel = 'K1:PEM-VOLT_REFL_TABLE_GND_OUT_DQ'\n",
    "group = channel.split(':')[1].split('_')[0]\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igwn-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
